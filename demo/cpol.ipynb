{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking Methods: CPOL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial/demo illustrates how THUNER can be applied to [CPOL](https://www.openradar.io/research-radars/cpol), a C-band dual-polarisation research radar located at Gunn Point near Darwin, in Australia's northern Territory. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import shutil\n",
    "import glob\n",
    "import thuner.data as data\n",
    "import thuner.option as option\n",
    "import thuner.track.track as track\n",
    "import thuner.visualize as visualize\n",
    "import thuner.analyze as analyze\n",
    "import thuner.default as default\n",
    "import thuner.attribute as attribute\n",
    "import thuner.parallel as parallel\n",
    "import thuner.utils as utils\n",
    "import thuner.config as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the local base directory for saving outputs\n",
    "base_local = config.get_outputs_directory()\n",
    "\n",
    "output_parent = base_local / \"runs/cpol/geographic\"\n",
    "options_directory = output_parent / \"options\"\n",
    "visualize_directory = output_parent / \"visualize\"\n",
    "\n",
    "# Remove the output parent directory if it already exists\n",
    "# if output_parent.exists():\n",
    "    # shutil.rmtree(output_parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to get the demo data for this tutorial, if you haven't already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the demo data\n",
    "remote_directory = \"s3://thuner-storage/THUNER_output/input_data/raw/cpol\"\n",
    "data.get_demo_data(base_local, remote_directory)\n",
    "remote_directory = \"s3://thuner-storage/THUNER_output/input_data/raw/\"\n",
    "remote_directory += \"era5_monthly_10S_129E_14S_133E\"\n",
    "data.get_demo_data(base_local, remote_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geographic Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPOL level 1b data is provided in cartesian coordinates. We can convert this data to \n",
    "geographic coordinates on the fly by specifying default grid options. We will also save\n",
    "this converted data to disk for use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset options\n",
    "start = \"2005-11-13T14:00:00\"\n",
    "# Note the CPOL times are usually a few seconds off the 10 m interval, so add 30 seconds\n",
    "# to ensure we capture 19:00:00\n",
    "end = \"2005-11-13T19:00:30\" \n",
    "times_dict = {\"start\": start, \"end\": end}\n",
    "cpol_options = data.aura.CPOLOptions(**times_dict, converted_options={\"save\": True})\n",
    "# cpol_options = data.aura.CPOLOptions(**times_dict, converted_options={\"load\": True})\n",
    "era5_dict = {\"latitude_range\": [-14, -10], \"longitude_range\": [129, 133]}\n",
    "era5_pl_options = data.era5.ERA5Options(**times_dict, **era5_dict)\n",
    "era5_dict.update({\"data_format\": \"single-levels\"})\n",
    "era5_sl_options = data.era5.ERA5Options(**times_dict, **era5_dict)\n",
    "datasets=[cpol_options, era5_pl_options, era5_sl_options]\n",
    "data_options = option.data.DataOptions(datasets=datasets)\n",
    "data_options.to_yaml(options_directory / \"data.yml\")\n",
    "\n",
    "# Create the grid_options\n",
    "grid_options = option.grid.GridOptions()\n",
    "grid_options.to_yaml(options_directory / \"grid.yml\")\n",
    "\n",
    "# Create the track_options\n",
    "track_options = default.track(dataset_name=\"cpol\")\n",
    "# Modify the default track options to demonstrate the tracking of both convective \n",
    "# objects, and mesoscale convective systems, which are built out of convective, middle \n",
    "# and stratiform echo objects, within the same THUNER run. We will use a larger\n",
    "# minimum size for the convective objects, as too many very small objects confuses the\n",
    "# matching algorithm.\n",
    "core = attribute.core.default_tracked()\n",
    "attributes = option.attribute.Attributes(name=\"convective\", attribute_types=[core])\n",
    "track_options.levels[0].object_by_name(\"convective\").attributes = attributes\n",
    "tint_tracking = option.track.TintOptions(search_margin=5)\n",
    "track_options.levels[0].object_by_name(\"convective\").tracking = tint_tracking\n",
    "mask_options = option.track.MaskOptions(save=True)\n",
    "track_options.levels[0].object_by_name(\"convective\").mask_options = mask_options\n",
    "track_options.levels[0].object_by_name(\"convective\").detection.min_area = 64\n",
    "track_options.levels[0].object_by_name(\"convective\").detection.altitudes\n",
    "track_options.levels[0].object_by_name(\"convective\").revalidate()\n",
    "track_options.levels[0].revalidate()\n",
    "# We will also modify the mcs tracking options to save a record of the member object ids\n",
    "mcs_attributes = track_options.levels[1].object_by_name(\"mcs\").attributes\n",
    "mcs_group_attr = mcs_attributes.attribute_type_by_name(\"group\")\n",
    "membership = attribute.group.build_membership_attribute_group()\n",
    "mcs_group_attr.attributes.append(membership)\n",
    "mcs_group_attr.revalidate()\n",
    "track_options.to_yaml(options_directory / \"track.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial, we will generate figures during runtime to visualize how THUNER\n",
    "is matching both convective and mcs objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the visualize_options\n",
    "kwargs = {\"visualize_directory\": visualize_directory, \"objects\": [\"convective\", \"mcs\"]}\n",
    "visualize_options = default.runtime(**kwargs)\n",
    "visualize_options.to_yaml(options_directory / \"visualize.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now perform our tracking run; note the run will be slow as we are generating runtime figures for both convective and MCS objects, and not using parallelization. To make the run go much faster, set `visualize_options = None` and use the the parallel tracking function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = utils.generate_times(data_options.dataset_by_name(\"cpol\").filepaths)\n",
    "args = [times, data_options, grid_options, track_options, visualize_options]\n",
    "# parallel.track(*args, output_directory=output_parent)\n",
    "track.track(*args, output_directory=output_parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once completed, outputs are available in the `output_parent` directory. The visualization\n",
    "folder will contain figures like that below, which illustrate the matching process. \n",
    "Currently THUNER supports the TINT/MINT matching approach, but the goal is to eventually \n",
    "incorporate others. Note that if viewing online, the figures below can be viewed at original scale by right clicking, save image as, and opening locally, or by right clicking, open in new tab, etc.\n",
    "\n",
    "![Visualization of the TINT/MINT matching process.](https://raw.githubusercontent.com/THUNER-project/THUNER/refs/heads/main/gallery/cpol_convective_match_20051113.png)\n",
    "\n",
    "Definitions of terms appearing in the above figure are provided by \n",
    "[Raut et al. (2021)](https://doi.org/10.1175/JAMC-D-20-0119.1). Note the displacement \n",
    "vector for the central orange object is large due to the object changing shape suddenly. \n",
    "Similar jumps occur when objects split and merge, and for this reason, object center displacements are ill suited to define object velocities. Instead, object velocities are calculated by smoothing the corrected local flow vectors, as discussed by [Short et al. (2023)](https://doi.org/10.1175/MWR-D-22-0146.1). Animations of all the runtime matching figures for the convective objects are provided below.\n",
    "\n",
    "![Convective object matching.](https://raw.githubusercontent.com/THUNER-project/THUNER/refs/heads/main/gallery/cpol_convective_match_20051113.gif)\n",
    "\n",
    "We also provide the matching figures for the MCS objects. Note there is only one MCS \n",
    "object, which is comprised of multiple disjoint convective objects; the grouping method\n",
    "is described by [Short et al. (2023)](https://doi.org/10.1175/MWR-D-22-0146.1).\n",
    "\n",
    "![MCS object matching.](https://raw.githubusercontent.com/THUNER-project/THUNER/refs/heads/main/gallery/cpol_mcs_match_20051113.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that when setting up the options above, we instructed THUNER to keep a record of the IDs of\n",
    "each member object (convective, middle and stratiform echoes) comprising each grouped \n",
    "mcs object. Note that only the mcs and convective objects are matched between times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = output_parent / \"attributes/mcs/group.csv\"\n",
    "columns = [\"convective_ids\", \"middle_ids\", \"anvil_ids\"]\n",
    "print(attribute.utils.read_attribute_csv(filepath, columns=columns).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also perform analysis on, and visualization of, the MCS objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_options = analyze.mcs.AnalysisOptions()\n",
    "analysis_options.to_yaml(options_directory / \"analysis.yml\")\n",
    "analyze.mcs.process_velocities(output_parent)\n",
    "analyze.mcs.quality_control(output_parent, analysis_options)\n",
    "analyze.mcs.classify_all(output_parent, analysis_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thuner.visualize.attribute import AttributeHandler, AttributeVisualizeMethod, LegendArtistMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "member_objects = [\"convective\", \"anvil\"]\n",
    "style = \"presentation\"\n",
    "\n",
    "base_qualities = [\"convective_contained\", \"anvil_contained\", \"duration\"]\n",
    "velocity_filepath = str(output_parent / \"analysis/velocities.csv\")\n",
    "quality_filepath = str(output_parent / \"analysis/quality.csv\")\n",
    "vis_func = visualize.attribute.velocity_horizontal\n",
    "color, label = \"tab:purple\", \"System Velocity\"\n",
    "vis_kwargs = {\"color\": color}\n",
    "method = AttributeVisualizeMethod(function=vis_func, keyword_arguments=vis_kwargs)\n",
    "leg_func = visualize.horizontal.displacement_legend_artist\n",
    "leg_kwargs = {\"color\": color, \"label\": label}\n",
    "legend_method = LegendArtistMethod(function=leg_func, keyword_arguments=leg_kwargs)\n",
    "kwargs = {\"name\": \"velocity\", \"attributes\": [\"u\", \"v\"], \"filepath\": velocity_filepath}\n",
    "kwargs.update({\"method\": method, \"label\": label, \"legend_method\": legend_method})\n",
    "kwargs.update({\"quality_filepath\": quality_filepath})\n",
    "kwargs.update({\"quality_variables\": base_qualities + [\"velocity\", \"duration\"]})\n",
    "velocity_handler = AttributeHandler(**kwargs)\n",
    "\n",
    "color, label = \"tab:red\", \"Ambient Wind\"\n",
    "vis_kwargs = {\"color\": color}\n",
    "method = AttributeVisualizeMethod(function=vis_func, keyword_arguments=vis_kwargs)\n",
    "leg_func = visualize.horizontal.displacement_legend_artist\n",
    "leg_kwargs = {\"color\": color, \"label\": label}\n",
    "legend_method = LegendArtistMethod(function=leg_func, keyword_arguments=leg_kwargs)\n",
    "kwargs = {\"name\": \"ambient\", \"attributes\": [\"u_ambient\", \"v_ambient\"]}\n",
    "kwargs.update({\"method\": method, \"filepath\": velocity_filepath})\n",
    "kwargs.update({\"label\": label, \"legend_method\": legend_method})\n",
    "kwargs.update({\"quality_filepath\": quality_filepath})\n",
    "kwargs.update({\"quality_variables\": base_qualities + [\"duration\"]})\n",
    "ambient_handler = AttributeHandler(**kwargs)\n",
    "\n",
    "color, label = \"darkblue\", \"Ambient Shear\"\n",
    "vis_kwargs = {\"color\": color}\n",
    "method = AttributeVisualizeMethod(function=vis_func, keyword_arguments=vis_kwargs)\n",
    "leg_func = visualize.horizontal.displacement_legend_artist\n",
    "leg_kwargs = {\"color\": color, \"label\": label}\n",
    "legend_method = LegendArtistMethod(function=leg_func, keyword_arguments=leg_kwargs)\n",
    "kwargs = {\"name\": \"shear\", \"attributes\": [\"u_shear\", \"v_shear\"]}\n",
    "kwargs.update({\"method\": method, \"filepath\": velocity_filepath})\n",
    "kwargs.update({\"label\": label, \"legend_method\": legend_method})\n",
    "kwargs.update({\"quality_filepath\": quality_filepath})\n",
    "kwargs.update({\"quality_variables\": base_qualities + [\"shear\", \"duration\"]})\n",
    "shear_handler = AttributeHandler(**kwargs)\n",
    "\n",
    "color, label = \"darkgreen\", \"Relative System Velocity\"\n",
    "vis_kwargs = {\"color\": color}\n",
    "method = AttributeVisualizeMethod(function=vis_func, keyword_arguments=vis_kwargs)\n",
    "leg_func = visualize.horizontal.displacement_legend_artist\n",
    "leg_kwargs = {\"color\": color, \"label\": label}\n",
    "legend_method = LegendArtistMethod(function=leg_func, keyword_arguments=leg_kwargs)\n",
    "kwargs = {\"name\": \"relative\", \"attributes\": [\"u_relative\", \"v_relative\"]}\n",
    "kwargs.update({\"method\": method, \"filepath\": velocity_filepath})\n",
    "kwargs.update({\"label\": label, \"legend_method\": legend_method})\n",
    "kwargs.update({\"quality_filepath\": quality_filepath})\n",
    "quality_vars = base_qualities + [\"relative_velocity\", \"duration\"]\n",
    "kwargs.update({\"quality_variables\": quality_vars})\n",
    "relative_handler = AttributeHandler(**kwargs)\n",
    "\n",
    "vis_func = visualize.attribute.text_horizontal\n",
    "vis_kwargs = {\"labelled_attribute\": \"universal_id\"}\n",
    "method = AttributeVisualizeMethod(function=vis_func, keyword_arguments=vis_kwargs)\n",
    "kwargs = {\"name\": \"universal_id\", \"attributes\": [\"universal_id\"], \"filepath\": velocity_filepath}\n",
    "kwargs.update({\"method\": method, \"label\": \"Object ID\"})\n",
    "kwargs.update({\"quality_filepath\": quality_filepath})\n",
    "kwargs.update({\"quality_variables\": base_qualities})\n",
    "id_handler = AttributeHandler(**kwargs)\n",
    "\n",
    "group_filepath = str(output_parent / \"attributes/mcs/group.csv\")\n",
    "vis_func = visualize.attribute.displacement_horizontal\n",
    "color, label = \"tab:blue\", \"Stratiform Offset\"\n",
    "vis_kwargs = {\"color\": color}\n",
    "method = AttributeVisualizeMethod(function=vis_func, keyword_arguments=vis_kwargs)\n",
    "leg_func = visualize.horizontal.displacement_legend_artist\n",
    "leg_kwargs = {\"color\": color, \"label\": label}\n",
    "legend_method = LegendArtistMethod(function=leg_func, keyword_arguments=leg_kwargs)\n",
    "kwargs = {\"name\": \"offset\", \"attributes\": [\"x_offset\", \"y_offset\"]}\n",
    "kwargs.update({\"method\": method, \"filepath\": group_filepath})\n",
    "kwargs.update({\"label\": \"Stratiform Offset\"})\n",
    "kwargs.update({\"quality_filepath\": quality_filepath})\n",
    "kwargs.update({\"quality_variables\": base_qualities + [\"offset\", \"duration\"]})\n",
    "offset_handler_convective = AttributeHandler(**kwargs)\n",
    "vis_kwargs[\"reverse\"] = True\n",
    "method = AttributeVisualizeMethod(function=vis_func, keyword_arguments=vis_kwargs)\n",
    "kwargs[\"method\"] = method\n",
    "offset_handler_anvil = AttributeHandler(**kwargs)\n",
    "\n",
    "ellipse_filepath = str(output_parent / \"attributes/mcs/convective/ellipse.csv\")\n",
    "vis_func = visualize.attribute.orientation_horizontal\n",
    "method = AttributeVisualizeMethod(function=vis_func)\n",
    "label = \"Major Axis\"\n",
    "leg_func = visualize.horizontal.orientation_legend_artist\n",
    "leg_kwargs = {\"label\": label, \"style\": style}\n",
    "legend_method = LegendArtistMethod(function=leg_func, keyword_arguments=leg_kwargs)\n",
    "\n",
    "kwargs = {\"name\": \"orientation\", \"attributes\": [\"major\", \"orientation\"]}\n",
    "kwargs.update({\"method\": method, \"filepath\": ellipse_filepath, \"label\": label})\n",
    "kwargs.update({\"quality_filepath\": quality_filepath, \"legend_method\": legend_method})\n",
    "kwargs.update({\"quality_variables\": base_qualities + [\"axis_ratio\", \"duration\"]})\n",
    "orientation_handler = AttributeHandler(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convective_handlers = [id_handler, velocity_handler]\n",
    "convective_handlers += [offset_handler_convective, orientation_handler]\n",
    "anvil_handlers = [id_handler, offset_handler_anvil]\n",
    "attribute_handlers = dict(zip(member_objects, [convective_handlers, anvil_handlers]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from thuner.analyze.utils import read_options\n",
    "from thuner.visualize.attribute import get_color_angle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"cpol\"\n",
    "convective_label = \"convective\"\n",
    "\n",
    "output_directory = output_parent\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Visualize mcs attributes at specified times.\"\"\"\n",
    "plt.close(\"all\")\n",
    "original_backend = matplotlib.get_backend()\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "start_time = np.datetime64(start)\n",
    "end_time = np.datetime64(end)\n",
    "options = read_options(output_parent)\n",
    "track_options = options[\"track\"]\n",
    "if dataset_name is None:\n",
    "    try:\n",
    "        object_options = track_options.levels[0].object_by_name(convective_label)\n",
    "        dataset_name = object_options.dataset\n",
    "    except KeyError:\n",
    "        message = \"Could not infer dataset used for detection. Provide manually.\"\n",
    "        raise KeyError(message)\n",
    "\n",
    "masks_filepath = output_directory / \"masks/mcs.zarr\"\n",
    "masks = xr.open_dataset(masks_filepath, engine=\"zarr\")\n",
    "times = masks.time.values\n",
    "times = times[(times >= start_time) & (times <= end_time)]\n",
    "\n",
    "# Get colors\n",
    "color_angle_df = get_color_angle_df(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = utils.generate_times(data_options.dataset_by_name(\"cpol\").filepaths)\n",
    "times = list(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_filepath = output_directory / f\"records/filepaths/{dataset_name}.csv\"\n",
    "filepaths = attribute.utils.read_attribute_csv(record_filepath, columns=[dataset_name])\n",
    "time = times[11]\n",
    "\n",
    "figure_name = \"mcs_attributes\"\n",
    "kwargs = {\"style\": style, \"attributes\": [\"id\", \"velocity\", \"offset\"]}\n",
    "kwargs[\"object_name\"] = \"mcs\"\n",
    "figure_options = option.visualize.HorizontalAttributeOptions(name=figure_name, **kwargs)\n",
    "\n",
    "dt = 3600\n",
    "args = [time, filepaths, masks, output_directory, figure_options]\n",
    "args += [options, track_options, dataset_name, dt, color_angle_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import thuner.detect.detect as detect\n",
    "from thuner.utils import format_time\n",
    "from thuner.attribute.utils import read_attribute_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get object colors\n",
    "plt.close(\"all\")\n",
    "\n",
    "keys = color_angle_df.loc[color_angle_df[\"time\"] == time][\"universal_id\"].values\n",
    "values = color_angle_df.loc[color_angle_df[\"time\"] == time][\"color_angle\"].values\n",
    "values = [visualize.visualize.mask_colormap(v / (2 * np.pi)) for v in values]\n",
    "object_colors = dict(zip(keys, values))\n",
    "\n",
    "filepath = filepaths[dataset_name].loc[time]\n",
    "dataset_options = options[\"data\"].dataset_by_name(dataset_name)\n",
    "\n",
    "args = [time, filepath, track_options, options[\"grid\"]]\n",
    "ds, boundary_coords, simple_boundary_coords = dataset_options.convert_dataset(*args)\n",
    "del boundary_coords\n",
    "\n",
    "grid = dataset_options.grid_from_dataset(ds, \"reflectivity\", time)\n",
    "del ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_grid = detect.rebuild_processed_grid(grid, track_options, \"mcs\", 1)\n",
    "del grid\n",
    "mask = masks.sel(time=time)\n",
    "mask = mask.load()\n",
    "args = [output_directory, processed_grid, mask, simple_boundary_coords]\n",
    "args += [figure_options, options[\"grid\"]]\n",
    "figure_name = figure_options.name\n",
    "style = figure_options.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_options = options[\"grid\"]\n",
    "track_options = options[\"track\"]\n",
    "obj_name = figure_options.object_name\n",
    "\n",
    "grid = processed_grid\n",
    "time = grid.time.values\n",
    "\n",
    "try:\n",
    "    filepath = output_directory / \"analysis/quality.csv\"\n",
    "    kwargs = {\"times\": [time], \"columns\": [\"duration\", \"parents\"]}\n",
    "    object_quality = read_attribute_csv(filepath, **kwargs).loc[time]\n",
    "    object_quality = object_quality.any(axis=1).to_dict()\n",
    "except (FileNotFoundError, KeyError):\n",
    "    object_quality = None\n",
    "\n",
    "args = [grid, mask, grid_options, figure_options, member_objects]\n",
    "args += [simple_boundary_coords]\n",
    "kwargs = {\"object_colors\": object_colors, \"mask_quality\": object_quality}\n",
    "\n",
    "with plt.style.context(visualize.visualize.styles[style]), visualize.visualize.set_style(style):\n",
    "    figure_features = visualize.horizontal.grouped_mask(*args, **kwargs)\n",
    "    fig, subplot_axes, colorbar_axes, legend_axes = figure_features\n",
    "\n",
    "kwargs = {\"object_name\": \"mcs\", \"time\": time, \"grid\": grid, \"mask\": mask}\n",
    "kwargs.update({\"boundary_coordinates\": simple_boundary_coords})\n",
    "kwargs.update({\"attribute_handlers\": attribute_handlers})\n",
    "kwargs.update({\"member_objects\": member_objects})\n",
    "kwargs.update({\"figure\": fig, \"subplot_axes\": subplot_axes})\n",
    "kwargs.update({\"colorbar_axes\": colorbar_axes, \"legend_axes\": legend_axes})\n",
    "core_filepath = output_directory / f\"attributes/{obj_name}/core.csv\"\n",
    "kwargs[\"core_filepath\"] = str(core_filepath)\n",
    "base_directory = output_directory / f\"attributes/{obj_name}/\"\n",
    "filepaths_list = [str(base_directory / f\"{obj}/core.csv\") for obj in member_objects]\n",
    "kwargs[\"member_core_filepaths\"] = dict(zip(member_objects, filepaths_list))\n",
    "grouped_figure = visualize.attribute.GroupedObjectFigure(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thuner.attribute.utils import read_attribute_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_artists = {}\n",
    "attribute_artists = {}\n",
    "for i, obj in enumerate(grouped_figure.member_objects):\n",
    "    attribute_artists[obj] = {}\n",
    "    for handler in grouped_figure.attribute_handlers[obj]:\n",
    "        # Get attribute df\n",
    "        attribute_artists[obj][handler.name] = {}\n",
    "        attribute_df = read_attribute_csv(handler.filepath, times=[time])\n",
    "        kwargs = {\"times\": [time], \"columns\": handler.quality_variables}\n",
    "        quality_df = read_attribute_csv(handler.quality_filepath, **kwargs)\n",
    "        if handler.quality_method is \"all\":\n",
    "            quality_df = quality_df.all(axis=1)\n",
    "        elif handler.quality_method is \"any\":\n",
    "            quality_df = quality_df.any(axis=1)\n",
    "\n",
    "        try:\n",
    "            id_type = \"universal_id\"\n",
    "            object_ids = attribute_df.reset_index()[id_type].values\n",
    "        except KeyError:\n",
    "            id_type = \"id\"\n",
    "            object_ids = attribute_df.reset_index()[id_type].values\n",
    "\n",
    "        # Will also need to load in core attributes\n",
    "        ax = grouped_figure.subplot_axes[i]\n",
    "        core_filepath = grouped_figure.member_core_filepaths[obj]\n",
    "        core_df = read_attribute_csv(core_filepath, times=[time])\n",
    "        # Join the core attributes with the attribute df\n",
    "        # Prepend column names with handler name if necessary\n",
    "        for col in core_df.columns:\n",
    "            if col in attribute_df.columns:\n",
    "                core_df.rename(columns={col: f\"{handler.name}_{col}\"}, inplace=True)\n",
    "        attribute_df = attribute_df.join(core_df)\n",
    "\n",
    "        leg_method = handler.legend_method\n",
    "        if leg_method is not None and handler.name not in legend_artists.keys():\n",
    "            # Create the legend artist\n",
    "            func = leg_method.function\n",
    "            keyword_arguments = leg_method.keyword_arguments\n",
    "            legend_artist = func(**keyword_arguments)\n",
    "            legend_artists[handler.label] = legend_artist\n",
    "\n",
    "        for obj_id in object_ids:\n",
    "            # Add the attribute for the given object to the figure\n",
    "            object_df = attribute_df.xs(obj_id, level=id_type, drop_level=False)\n",
    "            obj_quality_df = quality_df.xs(obj_id, level=id_type, drop_level=False)\n",
    "            attributes = handler.attributes\n",
    "            func = handler.method.function\n",
    "            kwargs = handler.method.keyword_arguments\n",
    "            artist = func(ax, attributes, object_df, obj_quality_df, **kwargs)\n",
    "            attribute_artists[obj][handler.name][obj_id] = artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcs_legend_options = {\"ncol\": 3, \"loc\": \"lower center\"}\n",
    "grouped_figure.legend_axes\n",
    "scale = visualize.utils.get_extent(grid_options)[1]\n",
    "handles, labels = list(legend_artists.values()), list(legend_artists.keys())\n",
    "handle, handler = visualize.horizontal.mask_legend_artist()\n",
    "handles += [handle]\n",
    "labels += [\"Object Masks\"]\n",
    "legend_color = visualize.visualize.figure_colors[figure_options.style][\"legend\"]\n",
    "\n",
    "args = [handles, labels]\n",
    "\n",
    "with plt.style.context(visualize.visualize.styles[style]), visualize.visualize.set_style(style):\n",
    "    if scale == 1:\n",
    "        legend = grouped_figure.legend_axes[0].legend(*args, **mcs_legend_options, handler_map=handler)\n",
    "    elif scale == 2:\n",
    "        mcs_legend_options[\"loc\"] = \"lower left\"\n",
    "        mcs_legend_options[\"bbox_to_anchor\"] = (-0.0, -0.425)\n",
    "        legend = grouped_figure.legend_axes[0].legend(*args, **mcs_legend_options, handler_map=handler)\n",
    "    legend.get_frame().set_alpha(None)\n",
    "    legend.get_frame().set_facecolor(legend_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_figure.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(visualize.visualize.styles[style]), visualize.visualize.set_style(style):\n",
    "\n",
    "    grid_options = options[\"grid\"]\n",
    "    track_options = options[\"track\"]\n",
    "    obj_name = figure_options.object_name\n",
    "\n",
    "    grid = processed_grid\n",
    "    time = grid.time.values\n",
    "\n",
    "    try:\n",
    "        filepath = output_directory / \"analysis/quality.csv\"\n",
    "        kwargs = {\"times\": [time], \"columns\": [\"duration\", \"parents\"]}\n",
    "        object_quality = read_attribute_csv(filepath, **kwargs).loc[time]\n",
    "        object_quality = object_quality.any(axis=1).to_dict()\n",
    "    except (FileNotFoundError, KeyError):\n",
    "        object_quality = None\n",
    "\n",
    "    member_objects = [\"convective\", \"anvil\"]\n",
    "\n",
    "    args = [grid, mask, grid_options, figure_options, member_objects]\n",
    "    args += [simple_boundary_coords]\n",
    "    kwargs = {\"object_colors\": object_colors, \"mask_quality\": object_quality}\n",
    "    fig, axes, colorbar_axes, legend_axes = visualize.horizontal.grouped_mask(*args, **kwargs)\n",
    "\n",
    "    try:\n",
    "        filepath = output_directory / f\"attributes/{obj_name}/core.csv\"\n",
    "        columns = [\"latitude\", \"longitude\"]\n",
    "        core = read_attribute_csv(filepath, times=[time], columns=columns).loc[time]\n",
    "        filepath = output_directory / \"attributes/mcs/group.csv\"\n",
    "        group = read_attribute_csv(filepath, times=[time]).loc[time]\n",
    "        filepath = output_directory / \"analysis/velocities.csv\"\n",
    "        velocities = read_attribute_csv(filepath, times=[time]).loc[time]\n",
    "        # filepath = output_directory / \"analysis/classification.csv\"\n",
    "        # classification = read_attribute_csv(filepath, times=[time]).loc[time]\n",
    "        filepath = output_directory / f\"attributes/mcs/{convective_label}/ellipse.csv\"\n",
    "        ellipse = read_attribute_csv(filepath, times=[time]).loc[time]\n",
    "        new_names = {\"latitude\": \"ellipse_latitude\", \"longitude\": \"ellipse_longitude\"}\n",
    "        ellipse = ellipse.rename(columns=new_names)\n",
    "        filepath = output_directory / \"analysis/quality.csv\"\n",
    "        quality = read_attribute_csv(filepath, times=[time]).loc[time]\n",
    "        attributes = pd.concat([core, ellipse, group, velocities, quality], axis=1)\n",
    "        objs = group.reset_index()[\"universal_id\"].values\n",
    "    except KeyError:\n",
    "        # If no attributes, set objs=[]\n",
    "        objs = []\n",
    "\n",
    "    for obj_id in objs:\n",
    "        obj_attr = attributes.loc[obj_id]\n",
    "        args = [axes, figure_options, obj_attr]\n",
    "        visualize.attribute.velocity_attributes_horizontal(*args, dt=dt)\n",
    "        visualize.attribute.displacement_attributes_horizontal(*args)\n",
    "        visualize.attribute.ellipse_attributes(*args)\n",
    "        if object_quality[obj_id]:\n",
    "            visualize.attribute.text_attributes_horizontal(*args, object_quality=object_quality)\n",
    "\n",
    "    style = figure_options.style\n",
    "    scale = visualize.utils.get_extent(grid_options)[1]\n",
    "\n",
    "    key_color = visualize.visualize.figure_colors[style][\"key\"]\n",
    "    visualize.horizontal.vector_key(axes[0], color=key_color, dt=dt, scale=scale)\n",
    "    kwargs = {\"mcs_name\": \"mcs\", \"mcs_level\": 1}\n",
    "    convective_label, stratiform_label = visualize.attribute.get_altitude_labels(track_options, **kwargs)\n",
    "\n",
    "    axes[0].set_title(convective_label)\n",
    "    axes[1].set_title(stratiform_label)\n",
    "\n",
    "    # Get legend proxy artists\n",
    "    handles = []\n",
    "    labels = []\n",
    "    handle = visualize.horizontal.domain_boundary_legend_artist()\n",
    "    handles += [handle]\n",
    "    labels += [\"Domain Boundary\"]\n",
    "    handle = visualize.horizontal.ellipse_legend_artist(\"Major Axis\", figure_options.style)\n",
    "    handles += [handle]\n",
    "    labels += [\"Major Axis\"]\n",
    "    attribute_names = figure_options.attributes\n",
    "    for name in [attr for attr in attribute_names if attr != \"id\"]:\n",
    "        color = visualize.attribute.colors_dispatcher[name]\n",
    "        label = visualize.attribute.label_dispatcher[name]\n",
    "        handle = visualize.horizontal.displacement_legend_artist(color, label)\n",
    "        handles.append(handle)\n",
    "        labels.append(label)\n",
    "\n",
    "    handle, handler = visualize.horizontal.mask_legend_artist()\n",
    "    handles += [handle]\n",
    "    labels += [\"Object Masks\"]\n",
    "    legend_color = visualize.visualize.figure_colors[figure_options.style][\"legend\"]\n",
    "    handles, labels = handles[::-1], labels[::-1]\n",
    "\n",
    "    mcs_legend_options = {\"ncol\": 3, \"loc\": \"lower center\"}\n",
    "\n",
    "    args = [handles, labels]\n",
    "    leg_ax = legend_axes[0]\n",
    "    if scale == 1:\n",
    "        legend = leg_ax.legend(*args, **mcs_legend_options, handler_map=handler)\n",
    "    elif scale == 2:\n",
    "        mcs_legend_options[\"loc\"] = \"lower left\"\n",
    "        mcs_legend_options[\"bbox_to_anchor\"] = (-0.0, -0.425)\n",
    "        legend = leg_ax.legend(*args, **mcs_legend_options, handler_map=handler)\n",
    "    legend.get_frame().set_alpha(None)\n",
    "    legend.get_frame().set_facecolor(legend_color)\n",
    "\n",
    "    # Remove mask and processed_grid from memory after generating the figure\n",
    "    del mask, processed_grid\n",
    "    filename = f\"{format_time(time)}.png\"\n",
    "    filepath = output_directory / f\"visualize/{figure_name}/{filename}\"\n",
    "    filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.show()\n",
    "    fig.savefig(filepath, bbox_inches=\"tight\")\n",
    "    visualize.utils.reduce_color_depth(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_name = \"mcs_attributes\"\n",
    "kwargs = {\"style\": \"presentation\", \"attributes\": [\"id\", \"velocity\", \"offset\"]}\n",
    "figure_options = option.visualize.HorizontalAttributeOptions(name=figure_name, **kwargs)\n",
    "\n",
    "args = [output_parent, start, end, figure_options]\n",
    "args_dict = {\"parallel_figure\": True, \"by_date\": False, \"num_processes\": 4}\n",
    "visualize.attribute.mcs_series(*args, **args_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Converted Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also perform THUNER tracking runs on general datasets, we just need to ensure \n",
    "they are pre-converted into a format recognized by THUNER, i.e. gridded data files readable by \n",
    "``xarray.open_dataset``, with variables named according to [CF-conventions](https://cfconventions.org/).\n",
    "To illustrate, we will use the converted CPOL files that were generated by the code in the\n",
    "previous section. We first modify the options used for the geographic coordinates above. Re-run\n",
    "the relevant cells above again if necessary. If you get a pydantic error, restart the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parent = base_local / \"runs/cpol/pre_converted\"\n",
    "options_directory = output_parent / \"options\"\n",
    "options_directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if output_parent.exists():\n",
    "    shutil.rmtree(output_parent)\n",
    "\n",
    "# Get the pre-converted filepaths\n",
    "base_filepath = base_local / \"input_data/converted/cpol/cpol_level_1b/v2020/gridded/\"\n",
    "base_filepath = base_filepath / \"grid_150km_2500m/2005/20051113\"\n",
    "filepaths = glob.glob(str(base_filepath / \"*.nc\"))\n",
    "filepaths = sorted(filepaths)\n",
    "\n",
    "# Create the data options. \n",
    "kwargs = {\"name\": \"cpol\", \"fields\": [\"reflectivity\"], \"filepaths\": filepaths}\n",
    "cpol_options = utils.BaseDatasetOptions(**times_dict, **kwargs)\n",
    "datasets=[cpol_options, era5_pl_options, era5_sl_options]\n",
    "data_options = option.data.DataOptions(datasets=datasets)\n",
    "data_options.to_yaml(options_directory / \"data.yml\")\n",
    "\n",
    "# Save other options\n",
    "grid_options.to_yaml(options_directory / \"grid.yml\")\n",
    "track_options.to_yaml(options_directory / \"track.yml\")\n",
    "\n",
    "# Switch off the runtime figures\n",
    "visualize_options = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = utils.generate_times(data_options.dataset_by_name(\"cpol\").filepaths)\n",
    "args = [times, data_options, grid_options, track_options, visualize_options]\n",
    "kwargs = {\"output_directory\": output_parent, \"dataset_name\": \"cpol\"}\n",
    "parallel.track(*args, **kwargs, debug_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_options = analyze.mcs.AnalysisOptions()\n",
    "analysis_options.to_yaml(options_directory / \"analysis.yml\")\n",
    "analyze.mcs.process_velocities(output_parent)\n",
    "analyze.mcs.quality_control(output_parent, analysis_options)\n",
    "analyze.mcs.classify_all(output_parent, analysis_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_name = \"mcs_attributes\"\n",
    "kwargs = {\"style\": \"presentation\", \"attributes\": [\"id\", \"velocity\", \"offset\"]}\n",
    "figure_options = option.visualize.HorizontalAttributeOptions(name=figure_name, **kwargs)\n",
    "\n",
    "args = [output_parent, start, end, figure_options]\n",
    "args_dict = {\"parallel_figure\": True, \"by_date\": False, \"num_processes\": 4}\n",
    "visualize.attribute.mcs_series(*args, **args_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note we can achieve the same result in this case by modifying `converted_options={\"save\": True}` to `converted_options={\"load\": True}` in the [Geographic Coordinates](#geographic-coordinates) section,and rerunning the cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cartesian Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the CPOL radar domains are small (150 km radii), it is reasonable to perform \n",
    "tracking in Cartesian coordinates. This should make the run faster as we are no longer \n",
    "performing regridding on the fly. We will also switch off the runtime figure generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parent = base_local / \"runs/cpol/cartesian\"\n",
    "options_directory = output_parent / \"options\"\n",
    "options_directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if output_parent.exists():\n",
    "    shutil.rmtree(output_parent)\n",
    "\n",
    "# Recreate the original cpol dataset options\n",
    "cpol_options = data.aura.CPOLOptions(**times_dict)\n",
    "datasets = [cpol_options, era5_pl_options, era5_sl_options]\n",
    "data_options = option.data.DataOptions(datasets=datasets)\n",
    "data_options.to_yaml(options_directory / \"data.yml\")\n",
    "\n",
    "# Create the grid_options\n",
    "grid_options = option.grid.GridOptions(name=\"cartesian\", regrid=False)\n",
    "grid_options.to_yaml(options_directory / \"grid.yml\")\n",
    "\n",
    "# Save the same track options from earlier\n",
    "track_options.to_yaml(options_directory / \"track.yml\")\n",
    "visualize_options = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = utils.generate_times(data_options.dataset_by_name(\"cpol\").filepaths)\n",
    "args = [times, data_options, grid_options, track_options, visualize_options]\n",
    "kwargs = {\"output_directory\": output_parent, \"dataset_name\": \"cpol\"}\n",
    "parallel.track(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_options = analyze.mcs.AnalysisOptions()\n",
    "analysis_options.to_yaml(options_directory / \"analysis.yml\")\n",
    "analyze.mcs.process_velocities(output_parent)\n",
    "analyze.mcs.quality_control(output_parent, analysis_options)\n",
    "analyze.mcs.classify_all(output_parent, analysis_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_name = \"mcs_attributes\"\n",
    "kwargs = {\"style\": \"presentation\", \"attributes\": [\"id\", \"velocity\", \"offset\"]}\n",
    "figure_options = option.visualize.HorizontalAttributeOptions(name=figure_name, **kwargs)\n",
    "\n",
    "args = [output_parent, start, end, figure_options]\n",
    "args_dict = {\"parallel_figure\": True, \"by_date\": False, \"num_processes\": 4}\n",
    "visualize.attribute.mcs_series(*args, **args_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "THUNER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
